# Портфолио Data Engineer
 
Проекты выполненные в рамках курса **Data Engineer** в **Яндекс.Практикум**

Ссылка|Задачи проекта|Стек технологий
-|-|-
**Готовится** | Построить `DWH` для нескольких источников данных. Построить пайплайн обновления данных. | **`SQL`, `NoSQL`, `MongoDB`, `Python`, `Airflow`**
**Готовится** | Построить аналитическое хранилище на базе `Vertica` | **`Vertica`, `Airflow`**
**Готовится** | Реализовать систему рекомендаций на основе `Data Lake` | **`HDFS`, `Apache Spark`, `PySpark`, `Airflow`, `Python`**
[**pdf**](https://github.com/mustdayker/data_portfolio/blob/main/practicum_de/pdf/s_08_project_streaming_data_processing.pdf)|Реализовать сервис потоковой обработки данных | **`PostgreSQL`, `Apache Kafka`, `Spark Streaming`, `Python`**
[**pdf**](https://github.com/mustdayker/data_portfolio/blob/main/practicum_de/pdf/s_09_project_yandex_cloud.pdf)|Спроектировать и построить `DWH` с использованием облачных технологий `Yandex` | **`PostgreSQL`, `Redis`, `Apache Kafka`, `Kubernetes`, `Yandex Container Registry`, `Docker`**
[**pdf**](https://github.com/mustdayker/data_portfolio/blob/main/practicum_de/pdf/s_10_final_project.pdf)| Реализовать пайплайн обработки данных из нескольких источников. Настроить пайплайн переноса данных из слоя `staging` в витрину. Подключить `Metabase` к витрине данных и создать дашборд. | **`PostgreSQL`, `Vertica`, `Airflow`, `Metabase`, `Docker`**